{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Startup Delay Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "import json\n",
    "\n",
    "# Read from a file\n",
    "with open('data/Video_Startup_Delay_Inference/regression.json', 'r') as file:\n",
    "    results = json.load(file)\n",
    "    \n",
    "print(results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in results.keys():\n",
    "    print(\"Run {}:\".format(key))\n",
    "    for k in results[key].keys():\n",
    "        print(f\"{k}: {results[key][k]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burst_loss_keys = [key for key in results.keys() if not key.endswith('_0')]\n",
    "print(burst_loss_keys)\n",
    "prob_loss_keys = [key for key in results.keys() if key.endswith('_0') and not key.startswith('0_')]\n",
    "print(prob_loss_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = []\n",
    "dfs.append(pd.DataFrame({\"key\": \"No loss\", \"data\": [a - b for a, b in zip(results[\"0_0\"][\"real\"], results[\"0_0\"][\"predicted\"])]}))\n",
    "for key in prob_loss_keys:\n",
    "  data = [a - b for a, b in zip(results[key][\"real\"], results[key][\"predicted\"])]\n",
    "  dfs.append(pd.DataFrame({\"key\": \"$p$={}\\n \".format(float(key.split(\"_\")[0])/100.0), \"data\": data}))\n",
    "\n",
    "dfprob = pd.concat(dfs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = []\n",
    "dfs.append(pd.DataFrame({\"key\": \"No loss\", \"data\": [a - b for a, b in zip(results[\"0_0\"][\"real\"], results[\"0_0\"][\"predicted\"])]}))\n",
    "for key in burst_loss_keys:\n",
    "  data = [a - b for a, b in zip(results[key][\"real\"], results[key][\"predicted\"])]\n",
    "  dfs.append(pd.DataFrame({\"key\": \"$p_1$={} \\n$1-p_2$={}\".format(float(key.split(\"_\")[0])/100.0,float(key.split(\"_\")[1])), \"data\": data}))\n",
    "\n",
    "dfburst = pd.concat(dfs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfprob.groupby(\"key\")[\"data\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Solving fonttype error\n",
    "matplotlib.rcParams['text.usetex'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "plt.figure(figsize=(6, 3))\n",
    "sns.boxplot(data=dfprob, y=\"data\", x=\"key\", fliersize=0)\n",
    "plt.xlabel('Loss rate')\n",
    "plt.ylabel('Error in ms \\n(real - predicted)')\n",
    "plt.grid(False)\n",
    "plt.ylim([-4000,3000])\n",
    "#plt.legend(ncol=2, loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/Video_Startup_Delay_Inference/regression_prob_box.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfburst.groupby(\"key\")[\"data\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "print(dfburst[\"key\"].unique())\n",
    "order = [\"No loss\",'$p_1$=0.005 \\n$1-p_2$=0.1','$p_1$=0.005 \\n$1-p_2$=0.01','$p_1$=0.01 \\n$1-p_2$=0.1','$p_1$=0.01 \\n$1-p_2$=0.01']\n",
    "filter=['$p_1$=0.005 \\n$1-p_2$=0.0001',\n",
    "        '$p_1$=0.01 \\n$1-p_2$=0.0001',\n",
    "        '$p_1$=0.005 \\n$1-p_2$=0.001',\n",
    "        '$p_1$=0.01 \\n$1-p_2$=0.001']\n",
    "sns.boxplot(data=dfburst[~dfburst[\"key\"].isin(filter)], y=\"data\",order=order,  x=\"key\", fliersize=0 )\n",
    "plt.xlabel('Loss rate')\n",
    "plt.ylabel('Error in ms \\n(real - predicted)')\n",
    "plt.grid(False)\n",
    "plt.ylim([-10000,2700])\n",
    "#plt.legend(ncol=2, loc='upper left', prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/Video_Startup_Delay_Inference/regression_burst_box.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = dfburst.copy()\n",
    "result = df.groupby('key')['data'].apply(lambda x: np.median(np.abs(x))).reset_index()\n",
    "result.columns = ['key', 'median_absolute_value']\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "plt.figure(figsize=(5, 2.5))\n",
    "ax = sns.ecdfplot(data=dfprob, x=\"data\", hue=\"key\")\n",
    "plt.xlabel('Error in seconds (real - predicted)')\n",
    "plt.ylabel('CDF')\n",
    "plt.grid(False)\n",
    "plt.xlim([-5000,5000])\n",
    "# ax.legend(ncol=2, loc='upper left', prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/Video_Startup_Delay_Inference/regression_prob_cdf.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "plt.figure(figsize=(5, 2.5))\n",
    "ax = sns.ecdfplot(data=dfburst, x=\"data\", hue=\"key\")\n",
    "plt.xlabel('Error in seconds (real - predicted)')\n",
    "plt.ylabel('CDF')\n",
    "plt.grid(False)\n",
    "plt.xlim([-5000,5000])\n",
    "# ax.legend(labels=dfburst[\"key\"].unique(), ncol=2, loc='upper left', prop={'size': 8})\n",
    "# ax.legend(labels=[\"No loss\", \"p_1=0.005 p_2=0.5\", \"p_1=0.005 p_2=0.1\", \"p_1=0.005 p_2=0.01\", \"p_1=0.01 p_2=0.5\", \"p_1=0.01 p_2=0.1\", \"p_1=0.01 p_2=0.01\"], ncol=2, loc='upper left', prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/Video_Startup_Delay_Inference/regression_burst_cdf.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"data/merged_cleaned_loss_dataset.pkl\")\n",
    "\n",
    "df = df[df[\"startup_time\"] >0]\n",
    "\n",
    "print(df[\"pcap_file\"].unique())\n",
    "\n",
    "df = df[(df[\"pcap_file\"] == \"cleaned.pcap\")  \n",
    "        # | (df[\"pcap_file\"] == \"loss_rate_10.0.pcap\") \n",
    "        # | (df[\"pcap_file\"] == \"loss_rate_5.0.pcap\")  \n",
    "        | (df[\"pcap_file\"] == \"loss_rate_0.5_0.1.pcap\") \n",
    "        | (df[\"pcap_file\"] == \"loss_rate_0.5_0.01.pcap\") \n",
    "        | (df[\"pcap_file\"] == \"loss_rate_1.0_0.1.pcap\") \n",
    "        | (df[\"pcap_file\"] == \"loss_rate_1.0_0.01.pcap\")\n",
    "        ]\n",
    "\n",
    "df[\"pcap_file\"] = df[\"pcap_file\"].replace({\n",
    "    \"cleaned.pcap\": \"No loss\",\n",
    "    # \"loss_rate_10.0.pcap\": \"$p$=0.1\",\n",
    "    # \"loss_rate_5.0.pcap\": \"$p$=0.05\",\n",
    "    \"loss_rate_0.5_0.1.pcap\": \"$p_1$=0.05 \\n$1-p_2$=0.1\",\n",
    "    \"loss_rate_0.5_0.01.pcap\": \"$p_1$=0.05 \\n$1-p_2$=0.01\",\n",
    "    \"loss_rate_1.0_0.1.pcap\": \"$p_1$=0.1 \\n$1-p_2$=0.1\",\n",
    "    \"loss_rate_1.0_0.01.pcap\": \"$p_1$=0.1 \\n$1-p_2$=0.01\",\n",
    "})\n",
    "plt.figure(figsize=(6, 3))\n",
    "sns.boxplot(data=df, y=\"segment_duration_avg\", x=\"pcap_file\", fliersize=0, order=[\"No loss\", \"$p_1$=0.05 \\n$1-p_2$=0.1\", \"$p_1$=0.05 \\n$1-p_2$=0.01\", \"$p_1$=0.1 \\n$1-p_2$=0.1\", \"$p_1$=0.1 \\n$1-p_2$=0.01\"])\n",
    "plt.xlabel('Loss rate')\n",
    "plt.ylabel('Average time \\n(seconds)')\n",
    "plt.grid(False)\n",
    "plt.ylim([-0.1,1.5])\n",
    "#plt.legend(ncol=2, loc='upper left', prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/Video_Startup_Delay_Inference/regression_segment_time_box.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_pickle(\"data/Video_Startup_Delay_Inference/cleaned_loss_dataset.pkl\")\n",
    "\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dfburst[~dfburst[\"key\"].isin(filter)]:\n",
    "    print(dfburst[\"data\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"data/Video_Startup_Delay_Inference/cleaned_loss_dataset.pkl\")\n",
    "\n",
    "df = df[df[\"startup_time\"] >0]\n",
    "\n",
    "# Get code to train models from server\n",
    "# Train the two models and run test sets\n",
    "\n",
    "df[\"folder\"].unique().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def do_train(df, target=\"startup_time\", fts=None, n_jobs=None, params=None):\n",
    "    rf = RandomForestRegressor(n_jobs=n_jobs)\n",
    "    hyperparameters = {\n",
    "    'RF': {'max_depth': 10,'min_samples_split': 10,},\n",
    "    }\n",
    "    if fts is not None:\n",
    "        clf = TabularPredictor(label=target).fit(\n",
    "        train_data=df[fts+target],\n",
    "        hyperparameters=hyperparameters,\n",
    "        )\n",
    "    else: \n",
    "        clf = TabularPredictor(label=target).fit(\n",
    "        train_data=df,\n",
    "        hyperparameters=hyperparameters,\n",
    "        )\n",
    "    return clf\n",
    "\n",
    "\n",
    "def do_test(df, model, fts=None, target=\"startup_time\"):\n",
    "  if fts is not None:\n",
    "    x_test = df[fts]\n",
    "  else:\n",
    "    x_test = df.drop(target, axis=1)\n",
    "  y_test = df[target]\n",
    "\n",
    "  ret = {}\n",
    "\n",
    "  predictions = model.predict(x_test)\n",
    "  # ret[\"shape\"] = x_test.shape\n",
    "  # ret[\"real\"] = y_test.values.tolist()\n",
    "  # ret[\"predicted\"] = predictions.tolist()\n",
    "  ret[\"mean_absolute_error\"] = metrics.mean_absolute_error(y_test, predictions)\n",
    "  ret[\"mean_squared_error\"] = metrics.mean_squared_error(y_test, predictions)\n",
    "  ret[\"median_absolute_error\"] = metrics.median_absolute_error(y_test, predictions)\n",
    "  ret[\"root_mean_squared_error\"] =  metrics.root_mean_squared_error(y_test, predictions)\n",
    "  ret[\"r2_score\"] = metrics.r2_score(y_test, predictions)\n",
    "\n",
    "  return ret\n",
    "\n",
    "\n",
    "print(\"Prepare the dataset\")\n",
    "df = pd.read_pickle(\"data/Video_Startup_Delay_Inference/merged_cleaned_loss_dataset.pkl\")\n",
    "\n",
    "df = df[df[\"startup_time\"] >0]\n",
    "\n",
    "# Get unique folder values\n",
    "unique_folders = df['folder'].unique()\n",
    "\n",
    "# Split the unique folders into train and test sets (80/20 split)\n",
    "train, test = train_test_split(unique_folders, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and test dataframes\n",
    "train_df = df[df[\"pcap_file\"] == \"cleaned.pcap\"][df['folder'].isin(train)].drop(columns=['folder', 'filename', 'pcap_file', 'interval_start', 'interval_end','loss_rate', 'burst_rate'])\n",
    "\n",
    "results = {}\n",
    "\n",
    "# pairs = [[0.5, 0], [1.0, 0], [2.0, 0], [5.0, 0], [10.0, 0], \n",
    "#          [1, 0.1], [1, 0.01], [1, 0.001], [1, 0.0001], \n",
    "#          [0.5, 0.1], [0.5, 0.01], [0.5, 0.001], [0.5, 0.0001]]\n",
    "\n",
    "pairs = [[0.5, 0], [1.0, 0],\n",
    "         [1, 0.1], [1, 0.01], [1, 0.001], \n",
    "         [0.5, 0.1], [0.5, 0.01], [0.5, 0.001]]\n",
    "\n",
    "\n",
    "print(\"All model\")\n",
    "\n",
    "model = do_train(train_df)\n",
    "\n",
    "print(\"Test the model on 0 0\")\n",
    "results[\"0_0\"] = do_test(df[df[\"pcap_file\"] == \"cleaned.pcap\"][df['folder'].isin(test)].drop(columns=['folder', 'filename', 'pcap_file', 'interval_start', 'interval_end','loss_rate', 'burst_rate']), model)\n",
    "\n",
    "\n",
    "\n",
    "for pair in pairs:\n",
    "  print(\"Test the model on {} {}\".format(pair[0], pair[1]))\n",
    "  results[\"{}_{}\".format(pair[0], pair[1])] = do_test(df[(df[\"loss_rate\"] == pair[0]) & (df[\"burst_rate\"] == pair[1])][df['folder'].isin(test)].drop(columns=['folder', 'filename', 'pcap_file', 'interval_start', 'interval_end','loss_rate', 'burst_rate']), model)\n",
    "  \n",
    "  \n",
    "with open('data/Video_Startup_Delay_Inference/all.json', 'w') as file:\n",
    "  json.dump(results, file, indent=4)\n",
    "  \n",
    "print(\"Network model\") \n",
    "\n",
    "model = do_train(train_df.drop(columns=['segment_count',\n",
    "       'segment_size_min', 'segment_size_max', 'segment_size_avg',\n",
    "       'segment_size_std', 'segment_duration_min', 'segment_duration_max',\n",
    "       'segment_duration_avg', 'segment_duration_std', 'segment_gap_min',\n",
    "       'segment_gap_max', 'segment_gap_avg', 'segment_gap_std']))\n",
    "\n",
    "print(\"Test the model on 0 0\")\n",
    "results[\"0_0\"] = do_test(df[df[\"pcap_file\"] == \"cleaned.pcap\"][df['folder'].isin(test)].drop(columns=['folder', 'filename', 'pcap_file', 'interval_start', 'interval_end','loss_rate', 'burst_rate','segment_count',\n",
    "       'segment_size_min', 'segment_size_max', 'segment_size_avg',\n",
    "       'segment_size_std', 'segment_duration_min', 'segment_duration_max',\n",
    "       'segment_duration_avg', 'segment_duration_std', 'segment_gap_min',\n",
    "       'segment_gap_max', 'segment_gap_avg', 'segment_gap_std']), model)\n",
    "\n",
    "\n",
    "\n",
    "for pair in pairs:\n",
    "  print(\"Test the model on {} {}\".format(pair[0], pair[1]))\n",
    "  results[\"{}_{}\".format(pair[0], pair[1])] = do_test(df[(df[\"loss_rate\"] == pair[0]) & (df[\"burst_rate\"] == pair[1])][df['folder'].isin(test)].drop(columns=['folder', 'filename', 'pcap_file', 'interval_start', 'interval_end','loss_rate', 'burst_rate','segment_count',\n",
    "       'segment_size_min', 'segment_size_max', 'segment_size_avg',\n",
    "       'segment_size_std', 'segment_duration_min', 'segment_duration_max',\n",
    "       'segment_duration_avg', 'segment_duration_std', 'segment_gap_min',\n",
    "       'segment_gap_max', 'segment_gap_avg', 'segment_gap_std']), model)\n",
    "  \n",
    "  \n",
    "with open('data/Video_Startup_Delay_Inference/network.json', 'w') as file:\n",
    "  json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Service Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "\n",
    "folder=\"data/service_recognition\"\n",
    "train_data = TabularDataset(folder+\"/TRAIN.csv.xz\")\n",
    "loss_rate = [0.0,0.5,1.0,2.0,5.0,10.0]\n",
    "markov = [0.1,0.01,0.001,0.0001]\n",
    "\n",
    "test_data = [TabularDataset(folder+f\"/TEST_{loss}.csv.xz\") for loss in loss_rate]\n",
    "markov_test = [TabularDataset(folder+f\"/TEST_{loss}_{m}.csv.xz\") for m in markov for loss in loss_rate[1:3]]\n",
    "list_markov = [f\"{loss}_{m}\" for m in markov for loss in loss_rate[1:3]]\n",
    "label = 'service'\n",
    "\n",
    "feature_subsets = [\n",
    "    # L3\n",
    "    [\n",
    "        \"out_counter\", \"in_counter\", \"out_bytes\", \"in_bytes\"\n",
    "    ],\n",
    "    # IAT\n",
    "    [\n",
    "        \"out_std_inter_arrival_time\", \"out_avg_inter_arrival_time\", \"out_med_inter_arrival_time\",\n",
    "        \"out_max_inter_arrival_time\", \"out_min_inter_arrival_time\", \"out_ske_inter_arrival_time\",\n",
    "        \"out_kur_inter_arrival_time\", \"in_std_inter_arrival_time\", \"in_avg_inter_arrival_time\",\n",
    "        \"in_med_inter_arrival_time\", \"in_max_inter_arrival_time\", \"in_min_inter_arrival_time\",\n",
    "        \"in_ske_inter_arrival_time\", \"in_kur_inter_arrival_time\"\n",
    "    ],\n",
    "    # TCP\n",
    "    [\n",
    "        \"out_std_bytes_per_packet\", \"out_avg_bytes_per_packet\", \"out_max_bytes_per_packet\",\n",
    "        \"out_min_bytes_per_packet\", \"in_std_bytes_per_packet\", \"in_avg_bytes_per_packet\",\n",
    "        \"in_max_bytes_per_packet\", \"in_min_bytes_per_packet\", \"out_std_rwnd\", \"out_avg_rwnd\",\n",
    "        \"out_max_rwnd\", \"out_min_rwnd\", \"in_std_rwnd\", \"in_avg_rwnd\", \"in_max_rwnd\",\n",
    "        \"in_min_rwnd\", \"out_syn_flags\", \"in_syn_flags\", \"out_ack_flags\", \"in_ack_flags\",\n",
    "        \"out_psh_flags\", \"in_psh_flags\", \"out_urg_flags\", \"in_urg_flags\", \"out_rst_flags\",\n",
    "        \"in_rst_flags\", \"out_fin_flags\", \"in_fin_flags\", \"out_goodput\", \"in_goodput\",\n",
    "        \"out_max_rtt\"\n",
    "    ],\n",
    "    # TCP Stat\n",
    "    [\n",
    "        \"out_med_bytes_per_packet\", \"out_kur_bytes_per_packet\", \"out_ske_bytes_per_packet\",\n",
    "        \"in_med_bytes_per_packet\", \"in_kur_bytes_per_packet\", \"in_ske_bytes_per_packet\",\n",
    "        \"out_med_rwnd\", \"out_kur_rwnd\", \"out_ske_rwnd\", \"in_med_rwnd\", \"in_kur_rwnd\",\n",
    "        \"in_ske_rwnd\", \"out_kur_rtt\"\n",
    "    ],\n",
    "    # Bytes in flight\n",
    "    [\n",
    "        \"out_std_bytes_in_flight\", \"out_avg_bytes_in_flight\", \"out_max_bytes_in_flight\",\n",
    "        \"out_min_bytes_in_flight\", \"out_ske_bytes_in_flight\", \"out_kur_bytes_in_flight\",\n",
    "        \"out_str_bytes_in_flight\", \"out_end_bytes_in_flight\", \"in_std_bytes_in_flight\",\n",
    "        \"in_avg_bytes_in_flight\", \"in_max_bytes_in_flight\", \"in_min_bytes_in_flight\",\n",
    "        \"in_ske_bytes_in_flight\", \"in_kur_bytes_in_flight\", \"in_str_bytes_in_flight\",\n",
    "        \"in_end_bytes_in_flight\"\n",
    "    ],\n",
    "    # Retransmit\n",
    "    [\n",
    "        \"out_std_retransmit\", \"out_avg_retransmit\", \"out_med_retransmit\", \"out_max_retransmit\",\n",
    "        \"out_min_retransmit\", \"out_ske_retransmit\", \"out_kur_retransmit\", \"out_zero_retransmit\",\n",
    "        \"out_one_retransmit\", \"out_two_retransmit\", \"out_x_retransmit\", \"in_std_retransmit\",\n",
    "        \"in_avg_retransmit\", \"in_med_retransmit\", \"in_max_retransmit\", \"in_min_retransmit\",\n",
    "        \"in_ske_retransmit\", \"in_kur_retransmit\", \"in_zero_retransmit\", \"in_one_retransmit\",\n",
    "        \"in_two_retransmit\", \"in_x_retransmit\", \"out_ooo_packets\", \"out_ooo_bytes\",\n",
    "        \"in_ooo_packets\", \"in_ooo_bytes\"\n",
    "    ],\n",
    "]\n",
    "\n",
    "hyperparameters = {\n",
    "        'RF': {'max_depth': 10,'min_samples_split': 10,},\n",
    "        }\n",
    "\n",
    "feature_combo = sum(feature_subsets,[])\n",
    "print(f\"Training model with features: {feature_combo}\")\n",
    "predictor = TabularPredictor(label=label).fit(\n",
    "    train_data=train_data[feature_combo + [label]],\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "models = []\n",
    "models.append((predictor, feature_combo))\n",
    "print(f\"Evaluate model with features: {feature_combo}\")\n",
    "metadata = {\"features\":feature_combo}\n",
    "\n",
    "\n",
    "basis = test_data[0]\n",
    "for i,test in enumerate(test_data):\n",
    "    test = test.reset_index(drop=True)\n",
    "    test = test.reindex(basis.index)\n",
    "    test[label] = test[label].fillna('WRONG')\n",
    "    result = predictor.evaluate(test,detailed_report=True)\n",
    "    result['confusion_matrix']=result['confusion_matrix'].to_json()\n",
    "    output=folder+f\"ml_output_{loss_rate[i]}.json\"\n",
    "    with open(output, 'w+') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            data = []\n",
    "        data.append({'features': feature_combo, 'result': result})\n",
    "        f.seek(0)\n",
    "        json.dump(data, f, indent=4)\n",
    "        f.truncate()\n",
    "for i,test in enumerate(markov_test):\n",
    "    test = test.reset_index(drop=True)\n",
    "    test = test.reindex(basis.index)\n",
    "    test[label] = test[label].fillna('WRONG')\n",
    "    result = predictor.evaluate(test,detailed_report=True)\n",
    "\n",
    "    result['confusion_matrix']=result['confusion_matrix'].to_json()\n",
    "    output=folder+f\"ml_output_{list_markov[i]}.json\"\n",
    "    with open(output, 'w+') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            data = []\n",
    "        data.append({'features': feature_combo, 'result': result})\n",
    "        f.seek(0)\n",
    "        json.dump(data, f, indent=4)\n",
    "        f.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
